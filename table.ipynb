{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, average_precision_score, matthews_corrcoef,\n",
        "    roc_curve, precision_recall_curve, auc\n",
        ")\n",
        "\n",
        "# ====== CONFIG ======\n",
        "ratios_dir = \"/Users/adithyamadduri/Desktop/Projects/proteomics_LGBM(ANML+Meta)_RATIOS_fixed_rfe\"\n",
        "baseline_dirs = [\n",
        "    \"/Users/adithyamadduri/Desktop/Projects/proteomics_LGBM(ANML+Meta)_BASELINE_demo_only\",\n",
        "    \"/Users/adithyamadduri/Desktop/Projects/proteomics_LGBM(ANML+Meta)_BASELINE_random\",\n",
        "    \"/Users/adithyamadduri/Desktop/Projects/proteomics_LGBM(ANML+Meta)_fixed\"\n",
        "]\n",
        "\n",
        "model_names = [\n",
        "    \"Proteomic Ratios\",\n",
        "    \"Demographics Only Baseline\",\n",
        "    \"Stratified Random Baseline\",\n",
        "    \"Raw Proteins + Demographics\"\n",
        "]\n",
        "\n",
        "classes = [\"MCI\", \"NCI\", \"AD\", \"AD+\"]\n",
        "seeds = [1, 2, 3, 4, 5]\n",
        "\n",
        "def safe_cls(c):\n",
        "    return c.replace(\"+\", \"plus\").replace(\" \", \"_\").replace(\"/\", \"-\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics(y_true, y_score, y_pred):\n",
        "    \"\"\"Compute all metrics for a given set of predictions.\"\"\"\n",
        "    metrics = {}\n",
        "    \n",
        "    # Basic classification metrics\n",
        "    metrics[\"Accuracy\"] = accuracy_score(y_true, y_pred)\n",
        "    metrics[\"Precision\"] = precision_score(y_true, y_pred, zero_division=0)\n",
        "    metrics[\"Recall\"] = recall_score(y_true, y_pred, zero_division=0)\n",
        "    metrics[\"F1_Score\"] = f1_score(y_true, y_pred, zero_division=0)\n",
        "    metrics[\"MCC\"] = matthews_corrcoef(y_true, y_pred)\n",
        "    \n",
        "    # ROC-AUC (using exact method from AD_Ratios_Plotting)\n",
        "    if len(np.unique(y_true)) > 1 and y_true.sum() > 0 and y_true.sum() < len(y_true):\n",
        "        metrics[\"AUC\"] = roc_auc_score(y_true, y_score)\n",
        "    else:\n",
        "        metrics[\"AUC\"] = np.nan\n",
        "    \n",
        "    # Average Precision (using exact method from AD_Ratios_Plotting)\n",
        "    if len(np.unique(y_true)) > 1 and y_true.sum() > 0:\n",
        "        metrics[\"AP\"] = average_precision_score(y_true, y_score)\n",
        "    else:\n",
        "        metrics[\"AP\"] = np.nan\n",
        "    \n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_model_metrics(results_dir, classes, seeds):\n",
        "    \"\"\"Calculate mean metrics across seeds for each class.\"\"\"\n",
        "    all_results = []\n",
        "    \n",
        "    for cls in classes:\n",
        "        seed_metrics = []\n",
        "        \n",
        "        for seed in seeds:\n",
        "            file_path = os.path.join(results_dir, f\"seed{seed}_{safe_cls(cls)}.csv\")\n",
        "            \n",
        "            if not os.path.exists(file_path):\n",
        "                print(f\"Missing: {file_path}\")\n",
        "                continue\n",
        "            \n",
        "            df = pd.read_csv(file_path)\n",
        "            \n",
        "            if len(df) == 0:\n",
        "                continue\n",
        "            \n",
        "            y_true = df[\"y_true\"].astype(int).values\n",
        "            y_score = df[\"y_score\"].astype(float).values\n",
        "            \n",
        "            # Get binary predictions using 0.5 threshold\n",
        "            y_pred = (y_score >= 0.5).astype(int)\n",
        "            \n",
        "            # Compute metrics\n",
        "            metrics = compute_metrics(y_true, y_score, y_pred)\n",
        "            seed_metrics.append(metrics)\n",
        "        \n",
        "        # Average across seeds\n",
        "        if seed_metrics:\n",
        "            avg_metrics = {}\n",
        "            for key in seed_metrics[0].keys():\n",
        "                values = [m[key] for m in seed_metrics if not np.isnan(m[key])]\n",
        "                if values:\n",
        "                    avg_metrics[key] = np.mean(values)\n",
        "                    avg_metrics[f\"{key}_std\"] = np.std(values)\n",
        "                else:\n",
        "                    avg_metrics[key] = np.nan\n",
        "                    avg_metrics[f\"{key}_std\"] = np.nan\n",
        "            \n",
        "            avg_metrics[\"Class\"] = cls\n",
        "            all_results.append(avg_metrics)\n",
        "        else:\n",
        "            # No valid seeds for this class\n",
        "            all_results.append({\n",
        "                \"Class\": cls,\n",
        "                \"Accuracy\": np.nan, \"Accuracy_std\": np.nan,\n",
        "                \"Precision\": np.nan, \"Precision_std\": np.nan,\n",
        "                \"Recall\": np.nan, \"Recall_std\": np.nan,\n",
        "                \"F1_Score\": np.nan, \"F1_Score_std\": np.nan,\n",
        "                \"MCC\": np.nan, \"MCC_std\": np.nan,\n",
        "                \"AUC\": np.nan, \"AUC_std\": np.nan,\n",
        "                \"AP\": np.nan, \"AP_std\": np.nan\n",
        "            })\n",
        "    \n",
        "    return pd.DataFrame(all_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating metrics for Proteomic Ratios...\n",
            "Calculating metrics for Demographics Only Baseline...\n",
            "Calculating metrics for Stratified Random Baseline...\n",
            "Calculating metrics for Raw Proteins + Demographics...\n",
            "\n",
            "Metrics calculation complete!\n"
          ]
        }
      ],
      "source": [
        "# Calculate metrics for all models\n",
        "all_model_results = []\n",
        "\n",
        "# Ratios model\n",
        "print(\"Calculating metrics for Proteomic Ratios...\")\n",
        "ratios_df = calculate_model_metrics(ratios_dir, classes, seeds)\n",
        "ratios_df[\"Model\"] = model_names[0]\n",
        "all_model_results.append(ratios_df)\n",
        "\n",
        "# Baseline models\n",
        "for i, baseline_dir in enumerate(baseline_dirs):\n",
        "    print(f\"Calculating metrics for {model_names[i+1]}...\")\n",
        "    baseline_df = calculate_model_metrics(baseline_dir, classes, seeds)\n",
        "    baseline_df[\"Model\"] = model_names[i+1]\n",
        "    all_model_results.append(baseline_df)\n",
        "\n",
        "# Combine all results\n",
        "results_df = pd.concat(all_model_results, ignore_index=True)\n",
        "\n",
        "print(\"\\nMetrics calculation complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================================================================================================\n",
            "PERFORMANCE METRICS TABLE\n",
            "========================================================================================================================\n",
            "\n",
            "Total rows: 16 (4 models × 4 classes)\n",
            "Metrics averaged across 5 seeds: [1, 2, 3, 4, 5]\n",
            "\n",
            "========================================================================================================================\n",
            "                      Model Class Accuracy Accuracy_std Precision Precision_std Recall Recall_std F1_Score F1_Score_std     MCC MCC_std    AUC AUC_std     AP AP_std\n",
            "           Proteomic Ratios   MCI   0.7094       0.0118    0.4638        0.0399 0.2951     0.0544   0.3590       0.0493  0.1925  0.0471 0.6495  0.0293 0.4180 0.0304\n",
            "           Proteomic Ratios   NCI   0.6667       0.0251    0.6819        0.0320 0.6940     0.0213   0.6875       0.0211  0.3313  0.0510 0.7277  0.0330 0.7268 0.0490\n",
            "           Proteomic Ratios    AD   0.8335       0.0062    0.5556        0.0396 0.3207     0.0488   0.4024       0.0335  0.3324  0.0198 0.7899  0.0152 0.4998 0.0134\n",
            "           Proteomic Ratios   AD+   0.9802       0.0061    0.1333        0.1944 0.0900     0.1114   0.1030       0.1350  0.1027  0.1382 0.7684  0.1267 0.3351 0.1650\n",
            " Demographics Only Baseline   MCI   0.7200       0.0060    0.2870        0.3943 0.0278     0.0496   0.0442       0.0765  0.0397  0.0487 0.5508  0.0063 0.3349 0.0129\n",
            " Demographics Only Baseline   NCI   0.5833       0.0364    0.5850        0.0414 0.8012     0.1462   0.6665       0.0302  0.1594  0.0868 0.6447  0.0244 0.6555 0.0289\n",
            " Demographics Only Baseline    AD   0.8242       0.0030    0.2000        0.4000 0.0041     0.0082   0.0080       0.0160  0.0260  0.0520 0.6137  0.0367 0.2592 0.0401\n",
            " Demographics Only Baseline   AD+   0.9689       0.0112    0.0000        0.0000 0.0000     0.0000   0.0000       0.0000 -0.0133  0.0084 0.6218  0.0678 0.0332 0.0080\n",
            " Stratified Random Baseline   MCI   0.7221       0.0042    0.2000        0.4000 0.0026     0.0051   0.0051       0.0101  0.0193  0.0385 0.5195  0.0190 0.3067 0.0184\n",
            " Stratified Random Baseline   NCI   0.5054       0.0258    0.5252        0.0210 0.6634     0.0455   0.5857       0.0254 -0.0081  0.0542 0.4890  0.0386 0.5310 0.0456\n",
            " Stratified Random Baseline    AD   0.8235       0.0024    0.0000        0.0000 0.0000     0.0000   0.0000       0.0000  0.0000  0.0000 0.4896  0.0312 0.1856 0.0100\n",
            " Stratified Random Baseline   AD+   0.9830       0.0013    0.0000        0.0000 0.0000     0.0000   0.0000       0.0000  0.0000  0.0000 0.5387  0.1087 0.0652 0.0777\n",
            "Raw Proteins + Demographics   MCI   0.7066       0.0118    0.1359        0.1700 0.0483     0.0653   0.0707       0.0934  0.0031  0.0552 0.5176  0.0240 0.3011 0.0231\n",
            "Raw Proteins + Demographics   NCI   0.6361       0.0382    0.6469        0.0427 0.6967     0.0496   0.6689       0.0308  0.2688  0.0780 0.6749  0.0414 0.6670 0.0443\n",
            "Raw Proteins + Demographics    AD   0.8300       0.0063    0.5832        0.0820 0.1207     0.0386   0.1982       0.0553  0.2067  0.0544 0.7161  0.0180 0.4102 0.0311\n",
            "Raw Proteins + Demographics   AD+   0.9788       0.0089    0.0000        0.0000 0.0000     0.0000   0.0000       0.0000 -0.0039  0.0079 0.6288  0.1325 0.0531 0.0344\n",
            "\n",
            "========================================================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Reorder columns for better presentation\n",
        "column_order = [\"Model\", \"Class\", \"Accuracy\", \"Accuracy_std\",\n",
        "                \"Precision\", \"Precision_std\", \"Recall\", \"Recall_std\",\n",
        "                \"F1_Score\", \"F1_Score_std\", \"MCC\", \"MCC_std\",\n",
        "                \"AUC\", \"AUC_std\", \"AP\", \"AP_std\"]\n",
        "\n",
        "# Ensure all columns exist\n",
        "for col in column_order:\n",
        "    if col not in results_df.columns:\n",
        "        results_df[col] = np.nan\n",
        "\n",
        "results_df = results_df[column_order]\n",
        "\n",
        "# Format the table for display\n",
        "display_df = results_df.copy()\n",
        "\n",
        "# Format numeric columns to 4 decimal places\n",
        "numeric_cols = [col for col in display_df.columns if col not in [\"Model\", \"Class\"]]\n",
        "for col in numeric_cols:\n",
        "    display_df[col] = display_df[col].apply(lambda x: f\"{x:.4f}\" if not pd.isna(x) else \"N/A\")\n",
        "\n",
        "print(\"=\" * 120)\n",
        "print(\"PERFORMANCE METRICS TABLE\")\n",
        "print(\"=\" * 120)\n",
        "print(f\"\\nTotal rows: {len(display_df)} (4 models × 4 classes)\")\n",
        "print(f\"Metrics averaged across {len(seeds)} seeds: {seeds}\")\n",
        "print(\"\\n\" + \"=\" * 120)\n",
        "print(display_df.to_string(index=False))\n",
        "print(\"\\n\" + \"=\" * 120)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========================================================================================================================\n",
            "FORMATTED PERFORMANCE TABLE (Mean ± Std)\n",
            "========================================================================================================================\n",
            "                      Model Class        Accuracy       Precision          Recall        F1_Score              MCC             AUC              AP\n",
            "           Proteomic Ratios   MCI 0.7094 ± 0.0118 0.4638 ± 0.0399 0.2951 ± 0.0544 0.3590 ± 0.0493  0.1925 ± 0.0471 0.6495 ± 0.0293 0.4180 ± 0.0304\n",
            "           Proteomic Ratios   NCI 0.6667 ± 0.0251 0.6819 ± 0.0320 0.6940 ± 0.0213 0.6875 ± 0.0211  0.3313 ± 0.0510 0.7277 ± 0.0330 0.7268 ± 0.0490\n",
            "           Proteomic Ratios    AD 0.8335 ± 0.0062 0.5556 ± 0.0396 0.3207 ± 0.0488 0.4024 ± 0.0335  0.3324 ± 0.0198 0.7899 ± 0.0152 0.4998 ± 0.0134\n",
            "           Proteomic Ratios   AD+ 0.9802 ± 0.0061 0.1333 ± 0.1944 0.0900 ± 0.1114 0.1030 ± 0.1350  0.1027 ± 0.1382 0.7684 ± 0.1267 0.3351 ± 0.1650\n",
            " Demographics Only Baseline   MCI 0.7200 ± 0.0060 0.2870 ± 0.3943 0.0278 ± 0.0496 0.0442 ± 0.0765  0.0397 ± 0.0487 0.5508 ± 0.0063 0.3349 ± 0.0129\n",
            " Demographics Only Baseline   NCI 0.5833 ± 0.0364 0.5850 ± 0.0414 0.8012 ± 0.1462 0.6665 ± 0.0302  0.1594 ± 0.0868 0.6447 ± 0.0244 0.6555 ± 0.0289\n",
            " Demographics Only Baseline    AD 0.8242 ± 0.0030 0.2000 ± 0.4000 0.0041 ± 0.0082 0.0080 ± 0.0160  0.0260 ± 0.0520 0.6137 ± 0.0367 0.2592 ± 0.0401\n",
            " Demographics Only Baseline   AD+ 0.9689 ± 0.0112 0.0000 ± 0.0000 0.0000 ± 0.0000 0.0000 ± 0.0000 -0.0133 ± 0.0084 0.6218 ± 0.0678 0.0332 ± 0.0080\n",
            " Stratified Random Baseline   MCI 0.7221 ± 0.0042 0.2000 ± 0.4000 0.0026 ± 0.0051 0.0051 ± 0.0101  0.0193 ± 0.0385 0.5195 ± 0.0190 0.3067 ± 0.0184\n",
            " Stratified Random Baseline   NCI 0.5054 ± 0.0258 0.5252 ± 0.0210 0.6634 ± 0.0455 0.5857 ± 0.0254 -0.0081 ± 0.0542 0.4890 ± 0.0386 0.5310 ± 0.0456\n",
            " Stratified Random Baseline    AD 0.8235 ± 0.0024 0.0000 ± 0.0000 0.0000 ± 0.0000 0.0000 ± 0.0000  0.0000 ± 0.0000 0.4896 ± 0.0312 0.1856 ± 0.0100\n",
            " Stratified Random Baseline   AD+ 0.9830 ± 0.0013 0.0000 ± 0.0000 0.0000 ± 0.0000 0.0000 ± 0.0000  0.0000 ± 0.0000 0.5387 ± 0.1087 0.0652 ± 0.0777\n",
            "Raw Proteins + Demographics   MCI 0.7066 ± 0.0118 0.1359 ± 0.1700 0.0483 ± 0.0653 0.0707 ± 0.0934  0.0031 ± 0.0552 0.5176 ± 0.0240 0.3011 ± 0.0231\n",
            "Raw Proteins + Demographics   NCI 0.6361 ± 0.0382 0.6469 ± 0.0427 0.6967 ± 0.0496 0.6689 ± 0.0308  0.2688 ± 0.0780 0.6749 ± 0.0414 0.6670 ± 0.0443\n",
            "Raw Proteins + Demographics    AD 0.8300 ± 0.0063 0.5832 ± 0.0820 0.1207 ± 0.0386 0.1982 ± 0.0553  0.2067 ± 0.0544 0.7161 ± 0.0180 0.4102 ± 0.0311\n",
            "Raw Proteins + Demographics   AD+ 0.9788 ± 0.0089 0.0000 ± 0.0000 0.0000 ± 0.0000 0.0000 ± 0.0000 -0.0039 ± 0.0079 0.6288 ± 0.1325 0.0531 ± 0.0344\n",
            "\n",
            "========================================================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Create a nicely formatted table with mean ± std format\n",
        "formatted_results = []\n",
        "\n",
        "for _, row in results_df.iterrows():\n",
        "    formatted_row = {\n",
        "        \"Model\": row[\"Model\"],\n",
        "        \"Class\": row[\"Class\"],\n",
        "        \"Accuracy\": f\"{row['Accuracy']:.4f} ± {row['Accuracy_std']:.4f}\" if not pd.isna(row['Accuracy']) else \"N/A\",\n",
        "        \"Precision\": f\"{row['Precision']:.4f} ± {row['Precision_std']:.4f}\" if not pd.isna(row['Precision']) else \"N/A\",\n",
        "        \"Recall\": f\"{row['Recall']:.4f} ± {row['Recall_std']:.4f}\" if not pd.isna(row['Recall']) else \"N/A\",\n",
        "        \"F1_Score\": f\"{row['F1_Score']:.4f} ± {row['F1_Score_std']:.4f}\" if not pd.isna(row['F1_Score']) else \"N/A\",\n",
        "        \"MCC\": f\"{row['MCC']:.4f} ± {row['MCC_std']:.4f}\" if not pd.isna(row['MCC']) else \"N/A\",\n",
        "        \"AUC\": f\"{row['AUC']:.4f} ± {row['AUC_std']:.4f}\" if not pd.isna(row['AUC']) else \"N/A\",\n",
        "        \"AP\": f\"{row['AP']:.4f} ± {row['AP_std']:.4f}\" if not pd.isna(row['AP']) else \"N/A\"\n",
        "    }\n",
        "    formatted_results.append(formatted_row)\n",
        "\n",
        "formatted_df = pd.DataFrame(formatted_results)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 120)\n",
        "print(\"FORMATTED PERFORMANCE TABLE (Mean ± Std)\")\n",
        "print(\"=\" * 120)\n",
        "print(formatted_df.to_string(index=False))\n",
        "print(\"\\n\" + \"=\" * 120)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saved detailed metrics to: /Users/adithyamadduri/Desktop/Projects/ratios_project/Finalized_Code/Results/performance_metrics_table.csv\n",
            "Saved formatted table to: /Users/adithyamadduri/Desktop/Projects/ratios_project/Finalized_Code/Results/performance_metrics_table_formatted.csv\n"
          ]
        }
      ],
      "source": [
        "# Save to CSV\n",
        "output_dir = \"/Users/adithyamadduri/Desktop/Projects/ratios_project/Finalized_Code/Results\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "csv_path = os.path.join(output_dir, \"performance_metrics_table.csv\")\n",
        "results_df.to_csv(csv_path, index=False)\n",
        "\n",
        "formatted_csv_path = os.path.join(output_dir, \"performance_metrics_table_formatted.csv\")\n",
        "formatted_df.to_csv(formatted_csv_path, index=False)\n",
        "\n",
        "print(f\"\\nSaved detailed metrics to: {csv_path}\")\n",
        "print(f\"Saved formatted table to: {formatted_csv_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========================================================================================================================\n",
            "SUMMARY: Best Model per Class\n",
            "========================================================================================================================\n",
            "Class   Best_AUC_Model Best_AUC_Value    Best_AP_Model Best_AP_Value    Best_F1_Model Best_F1_Value\n",
            "  MCI Proteomic Ratios         0.6495 Proteomic Ratios        0.4180 Proteomic Ratios        0.3590\n",
            "  NCI Proteomic Ratios         0.7277 Proteomic Ratios        0.7268 Proteomic Ratios        0.6875\n",
            "   AD Proteomic Ratios         0.7899 Proteomic Ratios        0.4998 Proteomic Ratios        0.4024\n",
            "  AD+ Proteomic Ratios         0.7684 Proteomic Ratios        0.3351 Proteomic Ratios        0.1030\n",
            "\n",
            "========================================================================================================================\n",
            "\n",
            "Saved summary to: /Users/adithyamadduri/Desktop/Projects/ratios_project/Finalized_Code/Results/performance_summary_best_models.csv\n"
          ]
        }
      ],
      "source": [
        "# Create a summary table showing best model per class for key metrics\n",
        "summary_data = []\n",
        "\n",
        "for cls in classes:\n",
        "    cls_data = results_df[results_df[\"Class\"] == cls].copy()\n",
        "    \n",
        "    # Find best model for each metric\n",
        "    best_auc_idx = cls_data[\"AUC\"].idxmax() if not cls_data[\"AUC\"].isna().all() else None\n",
        "    best_ap_idx = cls_data[\"AP\"].idxmax() if not cls_data[\"AP\"].isna().all() else None\n",
        "    best_f1_idx = cls_data[\"F1_Score\"].idxmax() if not cls_data[\"F1_Score\"].isna().all() else None\n",
        "    \n",
        "    summary_data.append({\n",
        "        \"Class\": cls,\n",
        "        \"Best_AUC_Model\": cls_data.loc[best_auc_idx, \"Model\"] if best_auc_idx is not None else \"N/A\",\n",
        "        \"Best_AUC_Value\": f\"{cls_data.loc[best_auc_idx, 'AUC']:.4f}\" if best_auc_idx is not None else \"N/A\",\n",
        "        \"Best_AP_Model\": cls_data.loc[best_ap_idx, \"Model\"] if best_ap_idx is not None else \"N/A\",\n",
        "        \"Best_AP_Value\": f\"{cls_data.loc[best_ap_idx, 'AP']:.4f}\" if best_ap_idx is not None else \"N/A\",\n",
        "        \"Best_F1_Model\": cls_data.loc[best_f1_idx, \"Model\"] if best_f1_idx is not None else \"N/A\",\n",
        "        \"Best_F1_Value\": f\"{cls_data.loc[best_f1_idx, 'F1_Score']:.4f}\" if best_f1_idx is not None else \"N/A\"\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 120)\n",
        "print(\"SUMMARY: Best Model per Class\")\n",
        "print(\"=\" * 120)\n",
        "print(summary_df.to_string(index=False))\n",
        "print(\"\\n\" + \"=\" * 120)\n",
        "\n",
        "# Save summary\n",
        "summary_csv_path = os.path.join(output_dir, \"performance_summary_best_models.csv\")\n",
        "summary_df.to_csv(summary_csv_path, index=False)\n",
        "print(f\"\\nSaved summary to: {summary_csv_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "neuro_240",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
